{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839},{"sourceId":11017890,"sourceType":"datasetVersion","datasetId":6860298},{"sourceId":11036714,"sourceType":"datasetVersion","datasetId":6874312},{"sourceId":11045044,"sourceType":"datasetVersion","datasetId":6880199},{"sourceId":11049091,"sourceType":"datasetVersion","datasetId":6883195},{"sourceId":11055588,"sourceType":"datasetVersion","datasetId":6887807},{"sourceId":11113694,"sourceType":"datasetVersion","datasetId":6929273},{"sourceId":11192316,"sourceType":"datasetVersion","datasetId":6987097},{"sourceId":11275614,"sourceType":"datasetVersion","datasetId":7049098},{"sourceId":11278122,"sourceType":"datasetVersion","datasetId":7050929},{"sourceId":11278172,"sourceType":"datasetVersion","datasetId":7050970}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install","metadata":{}},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"import fastai\nfrom fastai.vision.all import *\nfrom tqdm import tqdm\nfrom glob import glob","metadata":{"_uuid":"e97fa043-02da-4543-b1ac-513ffc44dec2","_cell_guid":"55935d31-2694-45da-a34a-94261649439c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:56.381982Z","iopub.execute_input":"2025-04-27T03:25:56.382274Z","iopub.status.idle":"2025-04-27T03:25:56.387378Z","shell.execute_reply.started":"2025-04-27T03:25:56.382255Z","shell.execute_reply":"2025-04-27T03:25:56.386584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SEED = 85\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(SEED)","metadata":{"_uuid":"08422815-d5d5-4f12-93bf-58e031e70dda","_cell_guid":"738a2e57-62b1-4cd1-970c-e9505a16a5b5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:56.388837Z","iopub.execute_input":"2025-04-27T03:25:56.389082Z","iopub.status.idle":"2025-04-27T03:25:56.405082Z","shell.execute_reply.started":"2025-04-27T03:25:56.389063Z","shell.execute_reply":"2025-04-27T03:25:56.404384Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nIMAGE_SIZE = [224, 224]\nBATCH_SIZE = 128\nEPOCHS = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:56.405945Z","iopub.execute_input":"2025-04-27T03:25:56.406196Z","iopub.status.idle":"2025-04-27T03:25:56.418723Z","shell.execute_reply.started":"2025-04-27T03:25:56.406175Z","shell.execute_reply":"2025-04-27T03:25:56.417902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels_train_val = pd.read_csv('/kaggle/input/data/train_val_list.txt')\nlabels_train_val.columns = ['Image_Index']\nlabels_test = pd.read_csv('/kaggle/input/data/test_list.txt')\nlabels_test.columns = ['Image_Index']\ndisease_labels = ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening',\n'Cardiomegaly', 'Nodule', 'Mass', 'Hernia']\n# NIH Dataset Labels CSV File \nlabels_df = pd.read_csv('/kaggle/input/data/Data_Entry_2017.csv')\nlabels_df.columns = ['Image_Index', 'Finding_Labels', 'Follow_Up_#', 'Patient_ID',\n                  'Patient_Age', 'Patient_Gender', 'View_Position',\n                  'Original_Image_Width', 'Original_Image_Height',\n                  'Original_Image_Pixel_Spacing_X',\n                  'Original_Image_Pixel_Spacing_Y', 'dfd']\n# One hot encoding\nfor diseases in tqdm(disease_labels): \n    labels_df[diseases] = labels_df['Finding_Labels'].map(lambda result: 1 if diseases in result else 0)\n\n# labels_df.to_csv('/kaggle/working/newData.csv')\nlabels_df=labels_df[labels_df.Finding_Labels != 'No Finding']\n#labels_df.head(3)","metadata":{"_uuid":"a146646c-ca7b-4441-869a-7407da42f4b0","_cell_guid":"4e4d9570-14a8-46bd-a77b-4c59057d578e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:56.420154Z","iopub.execute_input":"2025-04-27T03:25:56.420352Z","iopub.status.idle":"2025-04-27T03:25:57.130136Z","shell.execute_reply.started":"2025-04-27T03:25:56.420337Z","shell.execute_reply":"2025-04-27T03:25:57.129401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nlabels_df['Finding_Labels'] = labels_df['Finding_Labels'].apply(lambda s: [l for l in str(s).split('|')])\n\nnum_glob = glob('/kaggle/input/data/*/images/*.png')\nimg_path = {os.path.basename(x): x for x in num_glob}\n\nlabels_df['Paths'] = labels_df['Image_Index'].map(img_path.get)\nlabels_df.head()","metadata":{"_uuid":"5a632ffd-8096-481a-bc78-4192c1663625","_cell_guid":"e00c2fca-fb51-4231-a493-2b62f43b83eb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:57.130949Z","iopub.execute_input":"2025-04-27T03:25:57.131194Z","iopub.status.idle":"2025-04-27T03:25:57.438430Z","shell.execute_reply.started":"2025-04-27T03:25:57.131178Z","shell.execute_reply":"2025-04-27T03:25:57.437596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_patients = np.unique(labels_df['Patient_ID'])\nlen(unique_patients)","metadata":{"_uuid":"ba306f3c-3183-4087-8143-e385f83a22df","_cell_guid":"1052fa10-fd86-4042-ae7b-ec09fbba0d86","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:57.439292Z","iopub.execute_input":"2025-04-27T03:25:57.439504Z","iopub.status.idle":"2025-04-27T03:25:57.445660Z","shell.execute_reply.started":"2025-04-27T03:25:57.439487Z","shell.execute_reply":"2025-04-27T03:25:57.444825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# train-70\n# val-10\n# test-20\ntrain_val_df_patients, test_df_patients = train_test_split(unique_patients, \n                                   test_size = 0.2,\n                                   random_state = SEED,\n                                    shuffle= True\n                                   )\nlen(train_val_df_patients)","metadata":{"_uuid":"31d9e8b0-d79f-4b79-8f89-2bfaa6e7ab99","_cell_guid":"8ff1d9c5-1b3e-4747-8716-f0c811db89d8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:57.446442Z","iopub.execute_input":"2025-04-27T03:25:57.446710Z","iopub.status.idle":"2025-04-27T03:25:57.460222Z","shell.execute_reply.started":"2025-04-27T03:25:57.446690Z","shell.execute_reply":"2025-04-27T03:25:57.459576Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_val_df = labels_df[labels_df['Patient_ID'].isin(train_val_df_patients)]","metadata":{"_uuid":"5060ce8a-6576-434f-93f5-927f625d461a","_cell_guid":"dc7d2e26-3cd9-4631-9fc5-62e3b856893a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:57.462623Z","iopub.execute_input":"2025-04-27T03:25:57.463119Z","iopub.status.idle":"2025-04-27T03:25:57.490876Z","shell.execute_reply.started":"2025-04-27T03:25:57.463097Z","shell.execute_reply":"2025-04-27T03:25:57.490216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_val_df.head()","metadata":{"_uuid":"ce4122ec-3f90-4da8-ae78-6fb3ed4921c7","_cell_guid":"47af73dc-5657-479e-9a12-cf79a4f16807","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:57.491515Z","iopub.execute_input":"2025-04-27T03:25:57.491743Z","iopub.status.idle":"2025-04-27T03:25:57.508014Z","shell.execute_reply.started":"2025-04-27T03:25:57.491728Z","shell.execute_reply":"2025-04-27T03:25:57.507093Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels_df.shape\nprint('train_val size', train_val_df.shape[0])\nprint('test size', labels_df.shape[0] - train_val_df.shape[0])","metadata":{"_uuid":"d01adf34-18c5-49af-b3b5-338879c7cb31","_cell_guid":"1f8001a9-76cc-47ad-82af-9402d77c6173","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:57.508902Z","iopub.execute_input":"2025-04-27T03:25:57.509221Z","iopub.status.idle":"2025-04-27T03:25:57.517606Z","shell.execute_reply.started":"2025-04-27T03:25:57.509199Z","shell.execute_reply":"2025-04-27T03:25:57.516854Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data builder","metadata":{}},{"cell_type":"code","source":"item_transforms = [\n    Resize((224, 224)),\n]\n\nbatch_transforms = [\n    Flip(),\n    Rotate(),\n    Normalize.from_stats(*imagenet_stats),\n]\n\n\ndef get_x(row):\n    return row['Paths']\n\ndef get_y(row):\n    labels = row[disease_labels].tolist()\n    return labels\n\ndblock = DataBlock(\n    blocks=(ImageBlock, MultiCategoryBlock(encoded=True,vocab=disease_labels)),\n                   splitter=RandomSplitter(valid_pct=0.125, seed=SEED),\n                   get_x=get_x,\n                   get_y=get_y,\n                   item_tfms=item_transforms,\n                   batch_tfms=batch_transforms\n                  )\ndls = dblock.dataloaders(train_val_df, bs=64)\n# print(dblock.datasets(train_val_merge).train)","metadata":{"_uuid":"db273220-b8dd-4b32-b257-3e4f2a5f8cfa","_cell_guid":"a56c961f-a443-4ae9-8f9a-a52be3e90b99","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:57.518440Z","iopub.execute_input":"2025-04-27T03:25:57.518933Z","iopub.status.idle":"2025-04-27T03:25:57.773210Z","shell.execute_reply.started":"2025-04-27T03:25:57.518909Z","shell.execute_reply":"2025-04-27T03:25:57.772446Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torch.nn import functional as F\nfrom copy import deepcopy\n\n# Configuration block for all parameters\nclass ModelConfig:\n    # Momentum Encoder parameters\n    MOMENTUM = 0.9999\n    \n    # Spatial Attention parameters\n    ATTENTION_REDUCTION = 8\n    \n    # Memory Bank parameters\n    BANK_SIZE = 512\n    RARITY_THRESHOLD = 0.2\n    RETRIEVAL_K = 3\n    \n    # Model architecture parameters\n    DROPOUT_RATE = 0.3\n    HIDDEN_DIM = 512\n    \n    @staticmethod\n    def get_feature_dim(model_name):\n        if model_name == 'resnet50':\n            return 2048\n        elif model_name == 'densenet121':\n            return 1024\n        elif model_name in ['efficientnet_b0', 'efficientnet_b1']:\n            # This is a placeholder - actual value is determined at runtime\n            return None\n        else:\n            raise ValueError(f\"Model {model_name} not supported\")\n\n# Momentum Encoder: Simplified to final block copy\nclass MomentumFinalBlock(nn.Module):\n    def __init__(self, final_block, momentum=None):\n        super(MomentumFinalBlock, self).__init__()\n        self.momentum = momentum if momentum is not None else ModelConfig.MOMENTUM\n        self.final_block = deepcopy(final_block)\n        for param in self.final_block.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        return self.final_block(x)\n\n    def update(self, main_final_block):\n        for param_q, param_k in zip(main_final_block.parameters(), self.final_block.parameters()):\n            param_k.data = param_k.data * self.momentum + param_q.data * (1. - self.momentum)\n\n# Spatial Attention: Lightweight ROI selection\nclass SpatialAttention(nn.Module):\n    def __init__(self, in_channels, reduction=None):\n        super(SpatialAttention, self).__init__()\n        reduction = reduction if reduction is not None else ModelConfig.ATTENTION_REDUCTION\n        reduced_channels = max(in_channels // reduction, 8)\n        \n        self.conv1 = nn.Conv2d(in_channels, reduced_channels, kernel_size=1)\n        self.conv3 = nn.Conv2d(in_channels, reduced_channels, kernel_size=3, padding=1)\n        self.conv5 = nn.Conv2d(in_channels, reduced_channels, kernel_size=5, padding=2)\n        \n        self.spatial_att = nn.Sequential(\n            nn.Conv2d(reduced_channels * 3, 1, kernel_size=1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        f1 = self.conv1(x)\n        f3 = self.conv3(x)\n        f5 = self.conv5(x)\n        \n        features = torch.cat([f1, f3, f5], dim=1)\n        attention = self.spatial_att(features)  # [batch_size, 1, H, W]\n        return attention\n\n# Memory Bank: Store rare/important features\nclass MemoryBank(nn.Module):\n    def __init__(self, feature_dim, bank_size=None, rarity_threshold=None):\n        super(MemoryBank, self).__init__()\n        self.feature_dim = feature_dim\n        self.bank_size = bank_size if bank_size is not None else ModelConfig.BANK_SIZE\n        self.rarity_threshold = rarity_threshold if rarity_threshold is not None else ModelConfig.RARITY_THRESHOLD\n        \n        self.register_buffer('memory', torch.zeros(self.bank_size, feature_dim))\n        self.register_buffer('index', torch.tensor(0))\n\n    def update(self, features, rarity_scores):\n        batch_size = features.size(0)\n        mask = rarity_scores < self.rarity_threshold\n        rare_features = features[mask]\n        \n        if rare_features.size(0) > 0:\n            num_to_add = min(rare_features.size(0), self.bank_size - self.index.item())\n            if num_to_add > 0:\n                self.memory[self.index:self.index + num_to_add] = rare_features[:num_to_add]\n                self.index = (self.index + num_to_add) % self.bank_size\n\n    def retrieve(self, query, k=None):\n        k = k if k is not None else ModelConfig.RETRIEVAL_K\n        valid_memory = self.memory\n        if valid_memory.size(0) == 0:\n            return torch.zeros_like(query)\n        \n        norm_query = F.normalize(query, dim=1)\n        norm_memory = F.normalize(valid_memory, dim=1)\n        similarity = torch.matmul(norm_query, norm_memory.T)\n        \n        # Create a mask for entries where similarity != 1\n        mask = similarity != 1.0\n        \n        k = min(k, valid_memory.size(0))\n        \n        # Initialize containers for results\n        batch_size = query.size(0)\n        result = torch.zeros_like(query)\n        \n        for i in range(batch_size):\n            # Get indices where similarity is not 1 for this query\n            valid_indices = torch.where(mask[i])[0]\n            \n            if len(valid_indices) == 0:\n                # If all memories have similarity=1, just return zeros\n                continue\n            \n            # Get similarities only for valid indices\n            valid_similarities = similarity[i, valid_indices]\n            \n            # Get top-k among valid similarities\n            k_valid = min(k, valid_similarities.size(0))\n            weights, rel_indices = valid_similarities.topk(k_valid)\n            \n            # Convert relative indices to absolute indices\n            abs_indices = valid_indices[rel_indices]\n            \n            # Get features for these indices\n            retrieved = valid_memory[abs_indices]\n            \n            # Apply weights\n            weights = weights.unsqueeze(1).expand_as(retrieved)\n            weighted_features = (retrieved * weights).sum(dim=0)\n            \n            result[i] = weighted_features\n            \n        return result\n\n# Main Model\nclass ChestXrayModel(nn.Module):\n    def __init__(self, num_classes, model_name='efficientnet_b0', config=None):\n        super(ChestXrayModel, self).__init__()\n        \n        # Use provided config or the default ModelConfig\n        self.config = config if config is not None else ModelConfig\n        \n        # Backbone and Final Block\n        if model_name == 'resnet50':\n            self.base_model = models.resnet50(pretrained=True)\n            self.backbone = nn.Sequential(\n                self.base_model.conv1, self.base_model.bn1, self.base_model.relu,\n                self.base_model.maxpool, self.base_model.layer1, self.base_model.layer2,\n                self.base_model.layer3\n            )\n            self.final_block = self.base_model.layer4\n            self.feature_dim = 2048\n        elif model_name == 'densenet121':\n            self.base_model = models.densenet121(pretrained=True)\n            features = list(self.base_model.features.children())\n            self.backbone = nn.Sequential(*features[:-1])\n            self.final_block = nn.Sequential(features[-1])\n            self.feature_dim = 1024\n        elif model_name in ['efficientnet_b0', 'efficientnet_b1']:\n            self.base_model = models.efficientnet_v2_s(pretrained=True) if model_name == 'efficientnet_b0' else models.efficientnet_b1(pretrained=True)\n            features = list(self.base_model.features)\n            self.backbone = nn.Sequential(*features[:-1])\n            self.final_block = nn.Sequential(features[-1])\n            self.feature_dim = self.base_model.features[-1][0].out_channels\n        else:\n            raise ValueError(f\"Model {model_name} not supported\")\n\n        self.base_model.fc = nn.Identity() if hasattr(self.base_model, 'fc') else None\n        self.base_model.classifier = nn.Identity() if hasattr(self.base_model, 'classifier') else None\n\n        # Momentum Encoder\n        self.momentum_final_block = MomentumFinalBlock(self.final_block, momentum=self.config.MOMENTUM)\n\n        # Spatial Attention\n        self.spatial_attention = SpatialAttention(self.feature_dim, reduction=self.config.ATTENTION_REDUCTION)\n\n        # Memory Bank\n        self.memory_bank = MemoryBank(\n            self.feature_dim, \n            bank_size=self.config.BANK_SIZE, \n            rarity_threshold=self.config.RARITY_THRESHOLD\n        )\n\n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.BatchNorm1d(self.feature_dim),\n            nn.Linear(self.feature_dim, self.config.HIDDEN_DIM),\n            nn.ReLU(),\n            nn.Dropout(self.config.DROPOUT_RATE),\n            nn.Linear(self.config.HIDDEN_DIM, num_classes)\n        )\n        self.model_name = model_name\n\n    def forward(self, x):\n        # Extract features\n        backbone_features = self.backbone(x)\n        main_features = self.final_block(backbone_features)\n        with torch.no_grad():\n            momentum_features = self.momentum_final_block(backbone_features)\n\n        # Spatial attention and ROI extraction\n        attention_map = self.spatial_attention(main_features)\n        roi_features = main_features * attention_map\n        roi_pooled = F.adaptive_avg_pool2d(roi_features, (1, 1)).flatten(1)\n\n        # Momentum features\n        momentum_pooled = F.adaptive_avg_pool2d(momentum_features, (1, 1)).flatten(1)\n\n        # Combine ROI and momentum features (simple addition)\n        fused_features = roi_pooled + momentum_pooled\n\n        # Update and retrieve from memory bank\n        if self.training:\n            mean_norm = torch.mean(torch.norm(fused_features, dim=1))\n            rarity_scores = torch.abs(torch.norm(fused_features, dim=1) - mean_norm) / mean_norm\n            self.memory_bank.update(fused_features.detach(), rarity_scores)\n        \n        memory_features = self.memory_bank.retrieve(fused_features, k=self.config.RETRIEVAL_K)\n        enhanced_features = fused_features + memory_features\n\n        # Classification\n        out = self.classifier(enhanced_features)\n\n        # Update momentum encoder during training\n        if self.training:\n             self.momentum_final_block.update(self.final_block)\n\n        return out\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:57.774794Z","iopub.execute_input":"2025-04-27T03:25:57.775002Z","iopub.status.idle":"2025-04-27T03:25:57.802976Z","shell.execute_reply.started":"2025-04-27T03:25:57.774987Z","shell.execute_reply":"2025-04-27T03:25:57.802261Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train Script","metadata":{}},{"cell_type":"code","source":"from fastai.vision.all import *\nimport torch.nn as nn\nimport torch\nimport torchvision.models as models\nfrom copy import deepcopy\n\n# Focal Loss Implementation\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n        \"\"\"\n        Focal Loss to address class imbalance and hard sample mining\n        \n        Args:\n            alpha (float): Weighting factor for positive samples\n            gamma (float): Focusing parameter\n            reduction (str): Reduction method ('mean', 'sum', or 'none')\n        \"\"\"\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        \"\"\"\n        Compute focal loss\n        \n        Args:\n            inputs (torch.Tensor): Model predictions (logits)\n            targets (torch.Tensor): Ground truth labels\n        \n        Returns:\n            torch.Tensor: Computed loss\n        \"\"\"\n        # Apply sigmoid to convert logits to probabilities\n        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        \n        # Focal Loss modification\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n        \n        if self.reduction == 'mean':\n            return torch.mean(F_loss)\n        elif self.reduction == 'sum':\n            return torch.sum(F_loss)\n        else:\n            return F_loss\n\n# Asymmetric Loss Implementation\nclass AsymmetricLoss(nn.Module):\n    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, reduction='mean'):\n        \"\"\"\n        Asymmetric Loss to handle class imbalance and hard negative mining\n        \n        Args:\n            gamma_neg (float): Focusing parameter for negative samples\n            gamma_pos (float): Focusing parameter for positive samples\n            clip (float): Clip the predictions to prevent extreme values\n            eps (float): Small epsilon to prevent log(0)\n            reduction (str): Reduction method ('mean', 'sum', or 'none')\n        \"\"\"\n        super(AsymmetricLoss, self).__init__()\n        self.gamma_neg = gamma_neg\n        self.gamma_pos = gamma_pos\n        self.clip = clip\n        self.eps = eps\n        self.reduction = reduction\n\n    def forward(self, x, y):\n        \"\"\"\n        Compute asymmetric loss\n        \n        Args:\n            x (torch.Tensor): Model predictions (logits)\n            y (torch.Tensor): Ground truth labels\n        \n        Returns:\n            torch.Tensor: Computed loss\n        \"\"\"\n        # Convert to probabilities\n        x_sigmoid = torch.sigmoid(x)\n        \n        # Clip predictions to prevent extreme values\n        xs_min = x_sigmoid.clamp(min=self.eps)\n        xs_max = x_sigmoid.clamp(max=1-self.eps)\n        \n        # Asymmetric term for positive and negative samples\n        loss_pos = -y * torch.log(xs_min) * torch.pow(1 - xs_min, self.gamma_pos)\n        loss_neg = -(1 - y) * torch.log(1 - xs_max) * torch.pow(xs_max, self.gamma_neg)\n        \n        loss = loss_pos + loss_neg\n        \n        if self.reduction == 'mean':\n            return torch.mean(loss)\n        elif self.reduction == 'sum':\n            return torch.sum(loss)\n        else:\n            return loss\n\n# Create a custom fastai Learner for ChestXrayModel\ndef create_fastai_learner(\n    dls,                            # DataLoaders object\n    num_classes=14,                 # Number of output classes\n    lr=1e-4,                        # Learning rate\n    momentum=0.9,                   # Momentum for the momentum encoder (aligned with model)\n    dropout_rate=0.3,               # Dropout rate for classifier\n    mixup=False,                    # Whether to use mixup augmentation\n    wd=1e-2,                        # Weight decay\n    model=None,                     # Pass a pre-instantiated model if you have one\n    cbs=None,                       # Additional callbacks\n    warmup_epochs=0,                # Number of warm-up epochs for momentum encoder\n    loss_type='focal',              # Loss type: 'focal' or 'asymmetric'\n    focal_alpha=1,                  # Focal loss alpha parameter\n    focal_gamma=2,                  # Focal loss gamma parameter\n    asymmetric_gamma_neg=4,         # Asymmetric loss gamma for negative samples\n    asymmetric_gamma_pos=1          # Asymmetric loss gamma for positive samples\n):\n    # Create model if not provided\n    if model is None:\n        model = ChestXrayModel(\n            num_classes=num_classes\n        )\n    \n    # Register a custom callback to update momentum encoder with warm-up\n    class MomentumUpdateCallback(Callback):\n        def __init__(self, warmup_epochs):\n            super().__init__()\n            self.warmup_epochs = warmup_epochs\n        \n        def after_batch(self):\n            if hasattr(self.learn.model, 'momentum_final_block'):\n                # Apply warm-up during the first few epochs\n                is_warmup = self.learn.epoch < self.warmup_epochs\n                self.learn.model.momentum_final_block.update(\n                    self.learn.model.final_block, warmup=is_warmup\n                )\n    \n    # Define a custom loss function with multiple loss options\n    class ChestXrayLoss(Module):\n        def __init__(self, loss_type, **kwargs):\n            super().__init__()\n            if loss_type == 'focal':\n                self.loss = FocalLoss(\n                    #alpha=kwargs.get('focal_alpha', 1),\n                    #gamma=kwargs.get('focal_gamma', 2)\n                )\n            elif loss_type == 'asymmetric':\n                self.loss = AsymmetricLoss(\n                    gamma_neg=kwargs.get('asymmetric_gamma_neg', 4),\n                    gamma_pos=kwargs.get('asymmetric_gamma_pos', 1)\n                )\n            elif loss_type == 'bce':\n                self.loss = nn.BCEWithLogitsLoss()\n            else:\n                raise ValueError(f\"Unsupported loss type: {loss_type}\")\n        \n        def forward(self, preds, targets):\n            return self.loss(preds, targets)\n    \n    # Prepare default callbacks\n    default_cbs = [\n        MomentumUpdateCallback(warmup_epochs),  # Custom callback with warm-up\n        SaveModelCallback(monitor='valid_loss'),  # Save best model\n        EarlyStoppingCallback(monitor='valid_loss', patience=3)  # Early stopping\n    ]\n    \n    # Add user-specified callbacks\n    if cbs is not None:\n        if isinstance(cbs, list):\n            default_cbs.extend(cbs)\n        else:\n            default_cbs.append(cbs)\n    \n    # Create the learner with custom model and loss\n    learn = Learner(\n        dls, \n        model, \n        loss_func=ChestXrayLoss(\n            loss_type=loss_type, \n            focal_alpha=focal_alpha, \n            focal_gamma=focal_gamma,\n            asymmetric_gamma_neg=asymmetric_gamma_neg,\n            asymmetric_gamma_pos=asymmetric_gamma_pos\n        ),\n        metrics=[accuracy_multi, F1ScoreMulti(), RocAucMulti()],  # Multi-label metrics\n        wd=wd,\n        cbs=default_cbs\n    )\n    \n    # Modify the model's forward method to work with fastai's expectations\n    class ModelWrapper(nn.Module):\n        def __init__(self, model):\n            super().__init__()\n            self.model = model\n        \n        def forward(self, x):\n            return self.model(x)  # Model returns only class predictions\n    \n    # Wrap the model\n    learn.model = ModelWrapper(learn.model)\n    \n    # Enable mixed precision training if available\n    learn.to_fp16()\n    \n    # Add mixup if requested (suitable for multi-label with BCE)\n    if mixup:\n        learn.add_cb(MixUp())\n    \n    # Add a progress bar callback for better training visualization\n    learn.add_cb(ProgressCallback())\n    \n    # Add CSV logger to track metrics\n    learn.add_cb(CSVLogger())\n    \n    return learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:57.803840Z","iopub.execute_input":"2025-04-27T03:25:57.804035Z","iopub.status.idle":"2025-04-27T03:25:57.831358Z","shell.execute_reply.started":"2025-04-27T03:25:57.804019Z","shell.execute_reply":"2025-04-27T03:25:57.830740Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Stage 2","metadata":{}},{"cell_type":"code","source":"import fastai\nfrom fastai.vision.all import *\nfrom tqdm import tqdm\nfrom glob import glob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:57.832185Z","iopub.execute_input":"2025-04-27T03:25:57.832465Z","iopub.status.idle":"2025-04-27T03:25:57.850273Z","shell.execute_reply.started":"2025-04-27T03:25:57.832435Z","shell.execute_reply":"2025-04-27T03:25:57.849589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#learn = learn.load('/kaggle/working/models/fastai_momentum_cross_spatial_70_20_10')\nSEED = 85\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(SEED)\nlabels_train_val = pd.read_csv('/kaggle/input/data/train_val_list.txt')\nlabels_train_val.columns = ['Image_Index']\nlabels_test = pd.read_csv('/kaggle/input/data/test_list.txt')\nlabels_test.columns = ['Image_Index']\ndisease_labels = ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening',\n'Cardiomegaly', 'Nodule', 'Mass', 'Hernia']\n# NIH Dataset Labels CSV File \nlabels_df = pd.read_csv('/kaggle/input/data/Data_Entry_2017.csv')\nlabels_df.columns = ['Image_Index', 'Finding_Labels', 'Follow_Up_#', 'Patient_ID',\n                  'Patient_Age', 'Patient_Gender', 'View_Position',\n                  'Original_Image_Width', 'Original_Image_Height',\n                  'Original_Image_Pixel_Spacing_X',\n                  'Original_Image_Pixel_Spacing_Y', 'dfd']\n# One hot encoding\nfor diseases in tqdm(disease_labels): \n    labels_df[diseases] = labels_df['Finding_Labels'].map(lambda result: 1 if diseases in result else 0)\n\n# labels_df.to_csv('/kaggle/working/newData.csv')\n# labels_df=labels_df[labels_df.Finding_Labels != 'No Finding']\n# #labels_df.head(3)\n\nlabels_df['Finding_Labels'] = labels_df['Finding_Labels'].apply(lambda s: [l for l in str(s).split('|')])\n\nnum_glob = glob('/kaggle/input/data/*/images/*.png')\nimg_path = {os.path.basename(x): x for x in num_glob}\n\nlabels_df['Paths'] = labels_df['Image_Index'].map(img_path.get)\nlabels_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:57.851077Z","iopub.execute_input":"2025-04-27T03:25:57.851635Z","iopub.status.idle":"2025-04-27T03:25:59.121469Z","shell.execute_reply.started":"2025-04-27T03:25:57.851616Z","shell.execute_reply":"2025-04-27T03:25:59.120818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_patients = np.unique(labels_df['Patient_ID'])\nlen(unique_patients)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:59.122406Z","iopub.execute_input":"2025-04-27T03:25:59.122923Z","iopub.status.idle":"2025-04-27T03:25:59.129808Z","shell.execute_reply.started":"2025-04-27T03:25:59.122897Z","shell.execute_reply":"2025-04-27T03:25:59.128975Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# train-70\n# val-10\n# test-20\ntrain_val_df_patients, test_df_patients = train_test_split(unique_patients, \n                                   test_size = 0.2,\n                                   random_state = SEED,\n                                    shuffle= True\n                                   )\nlen(train_val_df_patients)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:59.130659Z","iopub.execute_input":"2025-04-27T03:25:59.131087Z","iopub.status.idle":"2025-04-27T03:25:59.147127Z","shell.execute_reply.started":"2025-04-27T03:25:59.131069Z","shell.execute_reply":"2025-04-27T03:25:59.146406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_val_df = labels_df[labels_df['Patient_ID'].isin(train_val_df_patients)]\ntest_df = labels_df[labels_df['Patient_ID'].isin(test_df_patients)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:59.148163Z","iopub.execute_input":"2025-04-27T03:25:59.148501Z","iopub.status.idle":"2025-04-27T03:25:59.196941Z","shell.execute_reply.started":"2025-04-27T03:25:59.148480Z","shell.execute_reply":"2025-04-27T03:25:59.196285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels_df.shape\nprint('train_val size', train_val_df.shape[0])\nprint('test size', labels_df.shape[0] - train_val_df.shape[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:59.199147Z","iopub.execute_input":"2025-04-27T03:25:59.199387Z","iopub.status.idle":"2025-04-27T03:25:59.203750Z","shell.execute_reply.started":"2025-04-27T03:25:59.199371Z","shell.execute_reply":"2025-04-27T03:25:59.203038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"item_transforms = [\n    Resize((224, 224)),\n]\n\nbatch_transforms = [\n    Flip(),\n    Rotate(),\n    Normalize.from_stats(*imagenet_stats),\n]\n\n\ndef get_x(row):\n    return row['Paths']\n\ndef get_y(row):\n    labels = row[disease_labels].tolist()\n    return labels\n\ndblock = DataBlock(\n    blocks=(ImageBlock, MultiCategoryBlock(encoded=True,vocab=disease_labels)),\n                   splitter=RandomSplitter(valid_pct=0.125, seed=SEED),\n                   get_x=get_x,\n                   get_y=get_y,\n                   item_tfms=item_transforms,\n                   batch_tfms=batch_transforms\n                  )\ndls_phase2 = dblock.dataloaders(train_val_df, bs=128)\ncbs_phase2=[\n    SaveModelCallback(monitor='valid_loss', min_delta=0.0001, with_opt=True),\n    EarlyStoppingCallback(monitor='valid_loss', min_delta=0.001, patience=5),\n    ShowGraphCallback()\n    ]\ndls_test = dblock.dataloaders(test_df, bs=32, shuffle=False)\n# print(dblock.datasets(train_val_merge).train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:59.204734Z","iopub.execute_input":"2025-04-27T03:25:59.205370Z","iopub.status.idle":"2025-04-27T03:25:59.980226Z","shell.execute_reply.started":"2025-04-27T03:25:59.205348Z","shell.execute_reply":"2025-04-27T03:25:59.979334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\ndef get_roc_auc(learner):\n    #arch = model_arch\n    # learner = vision_learner(dls, arch, metrics=[accuracy_multi, F1ScoreMulti(), RocAucMulti()])\n    # learner.model = torch.nn.DataParallel(learner.model)\n    # learner.load(model_path)\n    # learner.to('cuda')\n    learner.freeze()\n    preds, y_test = learner.get_preds(ds_idx=1)\n    roc_auc = roc_auc_score(y_test, preds)\n    \n    scores=[]\n    for i in range(0,14):\n        label_roc_auc_score=roc_auc_score(y_test[:,i],preds[:,i])\n        scores.append(label_roc_auc_score)\n    print('ROC_AUC_Labels:', list(zip(disease_labels,scores)))   \n    \n#     print('AVERAGE', sum(scores)/len(scores))\n    print(f'SCORE: {roc_auc}')\n    del learner\n    #gc.collect()\n    return {\n        'roc_auc': roc_auc,\n        'preds': preds,\n        'y_test': y_test\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:59.981085Z","iopub.execute_input":"2025-04-27T03:25:59.981354Z","iopub.status.idle":"2025-04-27T03:25:59.986637Z","shell.execute_reply.started":"2025-04-27T03:25:59.981330Z","shell.execute_reply":"2025-04-27T03:25:59.985955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from fastai.vision.all import *\n\n# cbs=[\n#     SaveModelCallback(monitor='valid_loss', min_delta=0.0001, with_opt=True),\n#     EarlyStoppingCallback(monitor='valid_loss', min_delta=0.001, patience=5),\n#     ShowGraphCallback()\n#     ]\n\n# learn = create_fastai_learner(dls,cbs=cbs,loss_type='bce')\n# lrs = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))\n# print('intial learning rate=', lrs.valley)\n# learn.fine_tune(freeze_epochs=3,epochs=20, base_lr=lrs.valley)\n# #learn.model = torch.nn.DataParallel(learn.model)\n# print('--------------Phase1-Done---------------')\n\n\n\n# print('--------------Begin-Phase2---------------')\n# learn = create_fastai_learner(dls_phase2,cbs=cbs_phase2,loss_type='asymmetric')\n# learn = learn.load('/kaggle/working/models/model')\n# learn.unfreeze()\n# learn.fit_one_cycle(5, slice(2e-5, 8e-5))\n# print('--------------Phase2-Done---------------')\n\n\n\n\n# print('--------------Begin-Testing---------------')\n# learn = create_fastai_learner(dls_test,cbs=cbs_phase2,loss_type='asymmetric')\n# learn = learn.load('/kaggle/working/models/model')\n# model_result= get_roc_auc(learn)\n# preds = modelv1_result['preds']\n# torch.save(preds, 'modelv1_result.pt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:25:59.987655Z","iopub.execute_input":"2025-04-27T03:25:59.988131Z","iopub.status.idle":"2025-04-27T03:26:00.007324Z","shell.execute_reply.started":"2025-04-27T03:25:59.988108Z","shell.execute_reply":"2025-04-27T03:26:00.006520Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from fastai.vision.all import *\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score\nimport itertools\nimport time\nimport os\n\n\n# Define the parameter grid\nmomentum_values = [0.99]\nk_values = [2, 3, 4, 5]\nthreshold_values = [0.2]\n\n# Define results directory\nresults_dir = '/kaggle/working/parameter_search_results'\nos.makedirs(results_dir, exist_ok=True)\n\n# Prepare to store results\nresults = []\n\n# Define base callbacks for all runs\nbase_cbs = [\n    SaveModelCallback(monitor='valid_loss', min_delta=0.0001, with_opt=True),\n    EarlyStoppingCallback(monitor='valid_loss', min_delta=0.001, patience=3),\n    ShowGraphCallback()\n    ]\ndef run_experiment(momentum, k, threshold, exp_name):\n    \"\"\"Run a single experiment with specified parameters.\"\"\"\n    print(f\"\\n=== Running experiment: momentum={momentum}, k={k}, threshold={threshold} ===\")\n    \n    # Modify the ModelConfig class attributes directly\n    ModelConfig.MOMENTUM = momentum\n    ModelConfig.RETRIEVAL_K = k\n    ModelConfig.RARITY_THRESHOLD = threshold\n    \n    # Create a model-specific save callback\n    save_cb = SaveModelCallback(monitor='valid_loss', min_delta=0.0001, \n                             fname=f\"model_{exp_name}\", with_opt=True)\n    \n    # Combine callbacks\n    cbs = base_cbs + [save_cb]\n    \n    try:\n        start_time = time.time()\n        \n        # Phase 1: Initial training\n        print('--------------Begin-Phase1---------------')\n        learn = create_fastai_learner(dls, cbs=cbs, loss_type='bce')\n        \n        # Find learning rate\n        lrs = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))\n        lr = lrs.valley if lrs.valley is not None else 1e-4\n        print('initial learning rate=', lr)\n        \n        # Training\n        learn.fine_tune(freeze_epochs=3, epochs=20, base_lr=lr)\n        \n        # Phase 2\n        print('--------------Phase1-Done---------------')\n        print('--------------Begin-Phase2---------------')\n        learn = create_fastai_learner(dls_phase2, cbs=cbs, loss_type='asymmetric')\n        learn = learn.load(f\"/kaggle/working/models/model_{exp_name}\")\n        learn.unfreeze()\n        learn.fit_one_cycle(5, slice(2e-5, 8e-5))\n        \n        # Testing phase\n        print('--------------Phase2-Done---------------')\n        print('--------------Begin-Testing---------------')\n        test_learn = create_fastai_learner(dls_test, cbs=cbs, loss_type='asymmetric')\n        test_learn = test_learn.load(f\"/kaggle/working/models/model_{exp_name}\")\n        \n        # Get results\n        model_result = get_roc_auc(test_learn)\n        preds = model_result['preds']\n        auc_scores = model_result['class_auc']\n        mean_auc = model_result['mean_auc']\n        \n        # Save predictions\n        torch.save(preds, f'{results_dir}/preds_{exp_name}.pt')\n        \n        training_time = time.time() - start_time\n        \n        result = {\n            'momentum': momentum,\n            'k': k,\n            'threshold': threshold,\n            'mean_auc': mean_auc,\n            'class_auc': auc_scores,\n            'training_time': training_time,\n            'exp_name': exp_name\n        }\n        \n        print(f\"Experiment completed. Mean AUC: {mean_auc:.4f}, Time: {training_time:.1f}s\")\n        return result\n        \n    except Exception as e:\n        print(f\"Error in experiment: {str(e)}\")\n        return {\n            'momentum': momentum,\n            'k': k,\n            'threshold': threshold,\n            'mean_auc': float('nan'),\n            'class_auc': [],\n            'training_time': float('nan'),\n            'exp_name': exp_name,\n            'error': str(e)\n        }\n\n# Main script\nif __name__ == \"__main__\":\n    # Get all parameter combinations\n    all_combinations = list(itertools.product(momentum_values, k_values, threshold_values))\n    total_experiments = len(all_combinations)\n    \n    print(f\"Starting grid search with {total_experiments} parameter combinations\")\n    \n    # Run all experiments\n    for i, (momentum, k, threshold) in enumerate(all_combinations):\n        exp_name = f\"m{momentum}_k{k}_t{threshold}\"\n        print(f\"\\nExperiment {i+1}/{total_experiments}\")\n        \n        result = run_experiment(momentum, k, threshold, exp_name)\n        results.append(result)\n        \n        # Save intermediate results after each experiment\n        pd.DataFrame(results).to_csv(f'{results_dir}/grid_search_results.csv', index=False)\n    \n    # Convert results to DataFrame for analysis\n    results_df = pd.DataFrame(results)\n    \n    # Find best parameters\n    if not results_df.empty and not all(np.isnan(results_df['mean_auc'])):\n        best_idx = results_df['mean_auc'].idxmax()\n        best_params = results_df.iloc[best_idx]\n        \n        print(\"\\n=== Best Parameter Combination ===\")\n        print(f\"Momentum: {best_params['momentum']}\")\n        print(f\"K-value: {best_params['k']}\")\n        print(f\"Threshold: {best_params['threshold']}\")\n        print(f\"Mean AUC: {best_params['mean_auc']:.4f}\")\n        print(f\"Experiment name: {best_params['exp_name']}\")\n        \n        # Create visualizations\n        \n        # 1. Heatmaps for each momentum value\n        for m in momentum_values:\n            df_m = results_df[results_df['momentum'] == m]\n            if not df_m.empty:\n                pivot = df_m.pivot_table(index='k', columns='threshold', values='mean_auc')\n                \n                plt.figure(figsize=(10, 8))\n                sns.heatmap(pivot, annot=True, fmt='.4f', cmap='viridis')\n                plt.title(f'Mean AUC for Momentum = {m}')\n                plt.tight_layout()\n                plt.savefig(f'{results_dir}/heatmap_momentum_{m}.png')\n                plt.close()\n        \n        # 2. Effect of individual parameters\n        plt.figure(figsize=(18, 6))\n        \n        # Effect of momentum\n        plt.subplot(1, 3, 1)\n        momentum_effect = results_df.groupby('momentum')['mean_auc'].mean().reset_index()\n        sns.barplot(x='momentum', y='mean_auc', data=momentum_effect)\n        plt.title('Effect of Momentum')\n        plt.ylim(momentum_effect['mean_auc'].min() * 0.99, momentum_effect['mean_auc'].max() * 1.01)\n        \n        # Effect of k\n        plt.subplot(1, 3, 2)\n        k_effect = results_df.groupby('k')['mean_auc'].mean().reset_index()\n        sns.barplot(x='k', y='mean_auc', data=k_effect)\n        plt.title('Effect of K Value')\n        plt.ylim(k_effect['mean_auc'].min() * 0.99, k_effect['mean_auc'].max() * 1.01)\n        \n        # Effect of threshold\n        plt.subplot(1, 3, 3)\n        threshold_effect = results_df.groupby('threshold')['mean_auc'].mean().reset_index()\n        sns.barplot(x='threshold', y='mean_auc', data=threshold_effect)\n        plt.title('Effect of Threshold')\n        plt.ylim(threshold_effect['mean_auc'].min() * 0.99, threshold_effect['mean_auc'].max() * 1.01)\n        \n        plt.tight_layout()\n        plt.savefig(f'{results_dir}/parameter_effects.png')\n        plt.close()\n        \n        # 3. Top 10 combinations\n        top10 = results_df.nlargest(10, 'mean_auc')\n        plt.figure(figsize=(14, 8))\n        \n        # Create labels for x-axis\n        labels = [f\"m={row['momentum']}\\nk={row['k']}\\nt={row['threshold']}\" for _, row in top10.iterrows()]\n        \n        plt.bar(range(len(labels)), top10['mean_auc'])\n        plt.xticks(range(len(labels)), labels, rotation=45, ha='right')\n        plt.title('Top 10 Parameter Combinations')\n        plt.ylabel('Mean AUC')\n        plt.tight_layout()\n        plt.savefig(f'{results_dir}/top10_combinations.png')\n        plt.close()\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T03:26:00.008191Z","iopub.execute_input":"2025-04-27T03:26:00.008493Z","execution_failed":"2025-04-27T03:28:59.768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}