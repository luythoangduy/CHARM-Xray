{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839},{"sourceId":11017890,"sourceType":"datasetVersion","datasetId":6860298},{"sourceId":11036714,"sourceType":"datasetVersion","datasetId":6874312},{"sourceId":11045044,"sourceType":"datasetVersion","datasetId":6880199},{"sourceId":11049091,"sourceType":"datasetVersion","datasetId":6883195},{"sourceId":11055588,"sourceType":"datasetVersion","datasetId":6887807},{"sourceId":11113694,"sourceType":"datasetVersion","datasetId":6929273},{"sourceId":11192316,"sourceType":"datasetVersion","datasetId":6987097},{"sourceId":11275614,"sourceType":"datasetVersion","datasetId":7049098},{"sourceId":11278122,"sourceType":"datasetVersion","datasetId":7050929},{"sourceId":11278172,"sourceType":"datasetVersion","datasetId":7050970},{"sourceId":12012230,"sourceType":"datasetVersion","datasetId":7557045}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install","metadata":{}},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"import fastai\nfrom fastai.vision.all import *\nfrom tqdm import tqdm\nfrom glob import glob","metadata":{"_uuid":"e97fa043-02da-4543-b1ac-513ffc44dec2","_cell_guid":"55935d31-2694-45da-a34a-94261649439c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:33.196394Z","iopub.execute_input":"2025-05-31T01:35:33.196656Z","iopub.status.idle":"2025-05-31T01:35:52.002187Z","shell.execute_reply.started":"2025-05-31T01:35:33.196631Z","shell.execute_reply":"2025-05-31T01:35:52.001486Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"SEED = 85\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(SEED)","metadata":{"_uuid":"08422815-d5d5-4f12-93bf-58e031e70dda","_cell_guid":"738a2e57-62b1-4cd1-970c-e9505a16a5b5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:52.003758Z","iopub.execute_input":"2025-05-31T01:35:52.004344Z","iopub.status.idle":"2025-05-31T01:35:52.019247Z","shell.execute_reply.started":"2025-05-31T01:35:52.004317Z","shell.execute_reply":"2025-05-31T01:35:52.018594Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nIMAGE_SIZE = [224, 224]\nBATCH_SIZE = 128\nEPOCHS = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:52.020053Z","iopub.execute_input":"2025-05-31T01:35:52.020329Z","iopub.status.idle":"2025-05-31T01:35:52.146825Z","shell.execute_reply.started":"2025-05-31T01:35:52.020306Z","shell.execute_reply":"2025-05-31T01:35:52.146013Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"labels_train_val = pd.read_csv('/kaggle/input/data/train_val_list.txt')\nlabels_train_val.columns = ['Image_Index']\nlabels_test = pd.read_csv('/kaggle/input/data/test_list.txt')\nlabels_test.columns = ['Image_Index']\ndisease_labels = ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening',\n'Cardiomegaly', 'Nodule', 'Mass', 'Hernia']\n# NIH Dataset Labels CSV File \nlabels_df = pd.read_csv('/kaggle/input/data/Data_Entry_2017.csv')\nlabels_df.columns = ['Image_Index', 'Finding_Labels', 'Follow_Up_#', 'Patient_ID',\n                  'Patient_Age', 'Patient_Gender', 'View_Position',\n                  'Original_Image_Width', 'Original_Image_Height',\n                  'Original_Image_Pixel_Spacing_X',\n                  'Original_Image_Pixel_Spacing_Y', 'dfd']\n# One hot encoding\nfor diseases in tqdm(disease_labels): \n    labels_df[diseases] = labels_df['Finding_Labels'].map(lambda result: 1 if diseases in result else 0)\n\n# labels_df.to_csv('/kaggle/working/newData.csv')\nlabels_df=labels_df[labels_df.Finding_Labels != 'No Finding']\n#labels_df.head(3)","metadata":{"_uuid":"a146646c-ca7b-4441-869a-7407da42f4b0","_cell_guid":"4e4d9570-14a8-46bd-a77b-4c59057d578e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:52.147725Z","iopub.execute_input":"2025-05-31T01:35:52.147971Z","iopub.status.idle":"2025-05-31T01:35:53.189193Z","shell.execute_reply.started":"2025-05-31T01:35:52.147949Z","shell.execute_reply":"2025-05-31T01:35:53.188184Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 14/14 [00:00<00:00, 25.53it/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\nlabels_df['Finding_Labels'] = labels_df['Finding_Labels'].apply(lambda s: [l for l in str(s).split('|')])\n\nnum_glob = glob('/kaggle/input/data/*/images/*.png')\nimg_path = {os.path.basename(x): x for x in num_glob}\n\nlabels_df['Paths'] = labels_df['Image_Index'].map(img_path.get)\nlabels_df.head()","metadata":{"_uuid":"5a632ffd-8096-481a-bc78-4192c1663625","_cell_guid":"e00c2fca-fb51-4231-a493-2b62f43b83eb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:53.191533Z","iopub.execute_input":"2025-05-31T01:35:53.191778Z","iopub.status.idle":"2025-05-31T01:35:55.184706Z","shell.execute_reply.started":"2025-05-31T01:35:53.191759Z","shell.execute_reply":"2025-05-31T01:35:55.183772Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        Image_Index             Finding_Labels  Follow_Up_#  Patient_ID  \\\n0  00000001_000.png             [Cardiomegaly]            0           1   \n1  00000001_001.png  [Cardiomegaly, Emphysema]            1           1   \n2  00000001_002.png   [Cardiomegaly, Effusion]            2           1   \n4  00000003_000.png                   [Hernia]            0           3   \n5  00000003_001.png                   [Hernia]            1           3   \n\n   Patient_Age Patient_Gender View_Position  Original_Image_Width  \\\n0           58              M            PA                  2682   \n1           58              M            PA                  2894   \n2           58              M            PA                  2500   \n4           81              F            PA                  2582   \n5           74              F            PA                  2500   \n\n   Original_Image_Height  Original_Image_Pixel_Spacing_X  ...  Emphysema  \\\n0                   2749                           0.143  ...          0   \n1                   2729                           0.143  ...          1   \n2                   2048                           0.168  ...          0   \n4                   2991                           0.143  ...          0   \n5                   2048                           0.168  ...          0   \n\n   Fibrosis  Effusion  Pneumonia  Pleural_Thickening  Cardiomegaly  Nodule  \\\n0         0         0          0                   0             1       0   \n1         0         0          0                   0             1       0   \n2         0         1          0                   0             1       0   \n4         0         0          0                   0             0       0   \n5         0         0          0                   0             0       0   \n\n   Mass  Hernia                                                  Paths  \n0     0       0  /kaggle/input/data/images_001/images/00000001_000.png  \n1     0       0  /kaggle/input/data/images_001/images/00000001_001.png  \n2     0       0  /kaggle/input/data/images_001/images/00000001_002.png  \n4     0       1  /kaggle/input/data/images_001/images/00000003_000.png  \n5     0       1  /kaggle/input/data/images_001/images/00000003_001.png  \n\n[5 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_Index</th>\n      <th>Finding_Labels</th>\n      <th>Follow_Up_#</th>\n      <th>Patient_ID</th>\n      <th>Patient_Age</th>\n      <th>Patient_Gender</th>\n      <th>View_Position</th>\n      <th>Original_Image_Width</th>\n      <th>Original_Image_Height</th>\n      <th>Original_Image_Pixel_Spacing_X</th>\n      <th>...</th>\n      <th>Emphysema</th>\n      <th>Fibrosis</th>\n      <th>Effusion</th>\n      <th>Pneumonia</th>\n      <th>Pleural_Thickening</th>\n      <th>Cardiomegaly</th>\n      <th>Nodule</th>\n      <th>Mass</th>\n      <th>Hernia</th>\n      <th>Paths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000001_000.png</td>\n      <td>[Cardiomegaly]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2682</td>\n      <td>2749</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000001_000.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000001_001.png</td>\n      <td>[Cardiomegaly, Emphysema]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2894</td>\n      <td>2729</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000001_001.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000001_002.png</td>\n      <td>[Cardiomegaly, Effusion]</td>\n      <td>2</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.168</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000001_002.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000003_000.png</td>\n      <td>[Hernia]</td>\n      <td>0</td>\n      <td>3</td>\n      <td>81</td>\n      <td>F</td>\n      <td>PA</td>\n      <td>2582</td>\n      <td>2991</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>/kaggle/input/data/images_001/images/00000003_000.png</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>00000003_001.png</td>\n      <td>[Hernia]</td>\n      <td>1</td>\n      <td>3</td>\n      <td>74</td>\n      <td>F</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.168</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>/kaggle/input/data/images_001/images/00000003_001.png</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"unique_patients = np.unique(labels_df['Patient_ID'])\nlen(unique_patients)","metadata":{"_uuid":"ba306f3c-3183-4087-8143-e385f83a22df","_cell_guid":"1052fa10-fd86-4042-ae7b-ec09fbba0d86","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:55.185656Z","iopub.execute_input":"2025-05-31T01:35:55.186386Z","iopub.status.idle":"2025-05-31T01:35:55.192742Z","shell.execute_reply.started":"2025-05-31T01:35:55.186354Z","shell.execute_reply":"2025-05-31T01:35:55.191936Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"14402"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# train-70\n# val-10\n# test-20\ntrain_val_df_patients, test_df_patients = train_test_split(unique_patients, \n                                   test_size = 0.2,\n                                   random_state = SEED,\n                                    shuffle= True\n                                   )\nlen(train_val_df_patients)","metadata":{"_uuid":"31d9e8b0-d79f-4b79-8f89-2bfaa6e7ab99","_cell_guid":"8ff1d9c5-1b3e-4747-8716-f0c811db89d8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:55.193753Z","iopub.execute_input":"2025-05-31T01:35:55.194026Z","iopub.status.idle":"2025-05-31T01:35:55.226726Z","shell.execute_reply.started":"2025-05-31T01:35:55.194001Z","shell.execute_reply":"2025-05-31T01:35:55.226034Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"11521"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_val_df = labels_df[labels_df['Patient_ID'].isin(train_val_df_patients)]","metadata":{"_uuid":"5060ce8a-6576-434f-93f5-927f625d461a","_cell_guid":"dc7d2e26-3cd9-4631-9fc5-62e3b856893a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:55.227563Z","iopub.execute_input":"2025-05-31T01:35:55.227839Z","iopub.status.idle":"2025-05-31T01:35:55.260081Z","shell.execute_reply.started":"2025-05-31T01:35:55.227815Z","shell.execute_reply":"2025-05-31T01:35:55.259425Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_val_df.head()","metadata":{"_uuid":"ce4122ec-3f90-4da8-ae78-6fb3ed4921c7","_cell_guid":"47af73dc-5657-479e-9a12-cf79a4f16807","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:55.260974Z","iopub.execute_input":"2025-05-31T01:35:55.261747Z","iopub.status.idle":"2025-05-31T01:35:55.279530Z","shell.execute_reply.started":"2025-05-31T01:35:55.261722Z","shell.execute_reply":"2025-05-31T01:35:55.278847Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"         Image_Index             Finding_Labels  Follow_Up_#  Patient_ID  \\\n0   00000001_000.png             [Cardiomegaly]            0           1   \n1   00000001_001.png  [Cardiomegaly, Emphysema]            1           1   \n2   00000001_002.png   [Cardiomegaly, Effusion]            2           1   \n12  00000004_000.png             [Mass, Nodule]            0           4   \n19  00000005_006.png             [Infiltration]            6           5   \n\n    Patient_Age Patient_Gender View_Position  Original_Image_Width  \\\n0            58              M            PA                  2682   \n1            58              M            PA                  2894   \n2            58              M            PA                  2500   \n12           82              M            AP                  2500   \n19           70              F            PA                  2992   \n\n    Original_Image_Height  Original_Image_Pixel_Spacing_X  ...  Emphysema  \\\n0                    2749                           0.143  ...          0   \n1                    2729                           0.143  ...          1   \n2                    2048                           0.168  ...          0   \n12                   2048                           0.168  ...          0   \n19                   2991                           0.143  ...          0   \n\n    Fibrosis  Effusion  Pneumonia  Pleural_Thickening  Cardiomegaly  Nodule  \\\n0          0         0          0                   0             1       0   \n1          0         0          0                   0             1       0   \n2          0         1          0                   0             1       0   \n12         0         0          0                   0             0       1   \n19         0         0          0                   0             0       0   \n\n    Mass  Hernia                                                  Paths  \n0      0       0  /kaggle/input/data/images_001/images/00000001_000.png  \n1      0       0  /kaggle/input/data/images_001/images/00000001_001.png  \n2      0       0  /kaggle/input/data/images_001/images/00000001_002.png  \n12     1       0  /kaggle/input/data/images_001/images/00000004_000.png  \n19     0       0  /kaggle/input/data/images_001/images/00000005_006.png  \n\n[5 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_Index</th>\n      <th>Finding_Labels</th>\n      <th>Follow_Up_#</th>\n      <th>Patient_ID</th>\n      <th>Patient_Age</th>\n      <th>Patient_Gender</th>\n      <th>View_Position</th>\n      <th>Original_Image_Width</th>\n      <th>Original_Image_Height</th>\n      <th>Original_Image_Pixel_Spacing_X</th>\n      <th>...</th>\n      <th>Emphysema</th>\n      <th>Fibrosis</th>\n      <th>Effusion</th>\n      <th>Pneumonia</th>\n      <th>Pleural_Thickening</th>\n      <th>Cardiomegaly</th>\n      <th>Nodule</th>\n      <th>Mass</th>\n      <th>Hernia</th>\n      <th>Paths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000001_000.png</td>\n      <td>[Cardiomegaly]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2682</td>\n      <td>2749</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000001_000.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000001_001.png</td>\n      <td>[Cardiomegaly, Emphysema]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2894</td>\n      <td>2729</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000001_001.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000001_002.png</td>\n      <td>[Cardiomegaly, Effusion]</td>\n      <td>2</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.168</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000001_002.png</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>00000004_000.png</td>\n      <td>[Mass, Nodule]</td>\n      <td>0</td>\n      <td>4</td>\n      <td>82</td>\n      <td>M</td>\n      <td>AP</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.168</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000004_000.png</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>00000005_006.png</td>\n      <td>[Infiltration]</td>\n      <td>6</td>\n      <td>5</td>\n      <td>70</td>\n      <td>F</td>\n      <td>PA</td>\n      <td>2992</td>\n      <td>2991</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000005_006.png</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"labels_df.shape\nprint('train_val size', train_val_df.shape[0])\nprint('test size', labels_df.shape[0] - train_val_df.shape[0])","metadata":{"_uuid":"d01adf34-18c5-49af-b3b5-338879c7cb31","_cell_guid":"1f8001a9-76cc-47ad-82af-9402d77c6173","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:55.280228Z","iopub.execute_input":"2025-05-31T01:35:55.280485Z","iopub.status.idle":"2025-05-31T01:35:55.285722Z","shell.execute_reply.started":"2025-05-31T01:35:55.280464Z","shell.execute_reply":"2025-05-31T01:35:55.284553Z"}},"outputs":[{"name":"stdout","text":"train_val size 41721\ntest size 10038\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Data builder","metadata":{}},{"cell_type":"code","source":"item_transforms = [\n    Resize((224, 224)),\n]\n\nbatch_transforms = [\n    Flip(),\n    Rotate(),\n    Normalize.from_stats(*imagenet_stats),\n]\n\n\ndef get_x(row):\n    return row['Paths']\n\ndef get_y(row):\n    labels = row[disease_labels].tolist()\n    return labels\n\ndblock = DataBlock(\n    blocks=(ImageBlock, MultiCategoryBlock(encoded=True,vocab=disease_labels)),\n                   splitter=RandomSplitter(valid_pct=0.125, seed=SEED),\n                   get_x=get_x,\n                   get_y=get_y,\n                   item_tfms=item_transforms,\n                   batch_tfms=batch_transforms\n                  )\ndls = dblock.dataloaders(train_val_df, bs=64)\n# print(dblock.datasets(train_val_merge).train)","metadata":{"_uuid":"db273220-b8dd-4b32-b257-3e4f2a5f8cfa","_cell_guid":"a56c961f-a443-4ae9-8f9a-a52be3e90b99","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:55.286559Z","iopub.execute_input":"2025-05-31T01:35:55.286848Z","iopub.status.idle":"2025-05-31T01:35:57.028128Z","shell.execute_reply.started":"2025-05-31T01:35:55.286826Z","shell.execute_reply":"2025-05-31T01:35:57.027387Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torch.nn import functional as F\nfrom copy import deepcopy\n\n# Configuration block for all parameters\nclass ModelConfig:\n    # Momentum Encoder parameters\n    MOMENTUM = 0.9999\n    \n    # Spatial Attention parameters\n    ATTENTION_REDUCTION = 8\n    \n    # Memory Bank parameters\n    BANK_SIZE = 512\n    RARITY_THRESHOLD = 0.2\n    RETRIEVAL_K = 3\n    \n    # Model architecture parameters\n    DROPOUT_RATE = 0.3\n    HIDDEN_DIM = 512\n    \n    @staticmethod\n    def get_feature_dim(model_name):\n        if model_name == 'resnet50':\n            return 2048\n        elif model_name == 'densenet121':\n            return 1024\n        elif model_name in ['efficientnet_b0', 'efficientnet_b1']:\n            # This is a placeholder - actual value is determined at runtime\n            return None\n        else:\n            raise ValueError(f\"Model {model_name} not supported\")\n\n# Momentum Encoder: Simplified to final block copy\nclass MomentumFinalBlock(nn.Module):\n    def __init__(self, final_block, momentum=None):\n        super(MomentumFinalBlock, self).__init__()\n        self.momentum = momentum if momentum is not None else ModelConfig.MOMENTUM\n        self.final_block = deepcopy(final_block)\n        for param in self.final_block.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        return self.final_block(x)\n\n    def update(self, main_final_block):\n        for param_q, param_k in zip(main_final_block.parameters(), self.final_block.parameters()):\n            param_k.data = param_k.data * self.momentum + param_q.data * (1. - self.momentum)\n\n# Spatial Attention: Lightweight ROI selection\nclass SpatialAttention(nn.Module):\n    def __init__(self, in_channels, reduction=None):\n        super(SpatialAttention, self).__init__()\n        reduction = reduction if reduction is not None else ModelConfig.ATTENTION_REDUCTION\n        reduced_channels = max(in_channels // reduction, 8)\n        \n        self.conv1 = nn.Conv2d(in_channels, reduced_channels, kernel_size=1)\n        self.conv3 = nn.Conv2d(in_channels, reduced_channels, kernel_size=3, padding=1)\n        self.conv5 = nn.Conv2d(in_channels, reduced_channels, kernel_size=5, padding=2)\n        \n        self.spatial_att = nn.Sequential(\n            nn.Conv2d(reduced_channels * 3, 1, kernel_size=1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        f1 = self.conv1(x)\n        f3 = self.conv3(x)\n        f5 = self.conv5(x)\n        \n        features = torch.cat([f1, f3, f5], dim=1)\n        attention = self.spatial_att(features)  # [batch_size, 1, H, W]\n        return attention\n\n# Memory Bank: Store rare/important features\nclass MemoryBank(nn.Module):\n    def __init__(self, feature_dim, bank_size=None, rarity_threshold=None):\n        super(MemoryBank, self).__init__()\n        self.feature_dim = feature_dim\n        self.bank_size = bank_size if bank_size is not None else ModelConfig.BANK_SIZE\n        self.rarity_threshold = rarity_threshold if rarity_threshold is not None else ModelConfig.RARITY_THRESHOLD\n        \n        self.register_buffer('memory', torch.zeros(self.bank_size, feature_dim))\n        self.register_buffer('index', torch.tensor(0))\n\n    def update(self, features, rarity_scores):\n        batch_size = features.size(0)\n        mask = rarity_scores < self.rarity_threshold\n        rare_features = features[mask]\n        \n        if rare_features.size(0) > 0:\n            num_to_add = min(rare_features.size(0), self.bank_size - self.index.item())\n            if num_to_add > 0:\n                self.memory[self.index:self.index + num_to_add] = rare_features[:num_to_add]\n                self.index = (self.index + num_to_add) % self.bank_size\n\n    def retrieve(self, query, k=None):\n        k = k if k is not None else ModelConfig.RETRIEVAL_K\n        valid_memory = self.memory\n        if valid_memory.size(0) == 0:\n            return torch.zeros_like(query)\n        \n        norm_query = F.normalize(query, dim=1)\n        norm_memory = F.normalize(valid_memory, dim=1)\n        similarity = torch.matmul(norm_query, norm_memory.T)\n        \n        # Create a mask for entries where similarity != 1\n        mask = similarity != 1.0\n        \n        k = min(k, valid_memory.size(0))\n        \n        # Initialize containers for results\n        batch_size = query.size(0)\n        result = torch.zeros_like(query)\n        \n        for i in range(batch_size):\n            # Get indices where similarity is not 1 for this query\n            valid_indices = torch.where(mask[i])[0]\n            \n            if len(valid_indices) == 0:\n                # If all memories have similarity=1, just return zeros\n                continue\n            \n            # Get similarities only for valid indices\n            valid_similarities = similarity[i, valid_indices]\n            \n            # Get top-k among valid similarities\n            k_valid = min(k, valid_similarities.size(0))\n            weights, rel_indices = valid_similarities.topk(k_valid)\n            \n            # Convert relative indices to absolute indices\n            abs_indices = valid_indices[rel_indices]\n            \n            # Get features for these indices\n            retrieved = valid_memory[abs_indices]\n            \n            # Apply weights\n            weights = weights.unsqueeze(1).expand_as(retrieved)\n            weighted_features = (retrieved * weights).sum(dim=0)\n            \n            result[i] = weighted_features\n            \n        return result\n\n# Main Model\nclass ChestXrayModel(nn.Module):\n    def __init__(self, num_classes, model_name='efficientnet_b0', config=None):\n        super(ChestXrayModel, self).__init__()\n        \n        # Use provided config or the default ModelConfig\n        self.config = config if config is not None else ModelConfig\n        \n        # Backbone and Final Block\n        if model_name == 'resnet50':\n            self.base_model = models.resnet50(pretrained=True)\n            self.backbone = nn.Sequential(\n                self.base_model.conv1, self.base_model.bn1, self.base_model.relu,\n                self.base_model.maxpool, self.base_model.layer1, self.base_model.layer2,\n                self.base_model.layer3\n            )\n            self.final_block = self.base_model.layer4\n            self.feature_dim = 2048\n        elif model_name == 'densenet121':\n            self.base_model = models.densenet121(pretrained=True)\n            features = list(self.base_model.features.children())\n            self.backbone = nn.Sequential(*features[:-1])\n            self.final_block = nn.Sequential(features[-1])\n            self.feature_dim = 1024\n        elif model_name in ['efficientnet_b0', 'efficientnet_b1']:\n            self.base_model = models.efficientnet_v2_s(pretrained=True) if model_name == 'efficientnet_b0' else models.efficientnet_b1(pretrained=True)\n            features = list(self.base_model.features)\n            self.backbone = nn.Sequential(*features[:-1])\n            self.final_block = nn.Sequential(features[-1])\n            self.feature_dim = self.base_model.features[-1][0].out_channels\n        else:\n            raise ValueError(f\"Model {model_name} not supported\")\n\n        self.base_model.fc = nn.Identity() if hasattr(self.base_model, 'fc') else None\n        self.base_model.classifier = nn.Identity() if hasattr(self.base_model, 'classifier') else None\n\n        # Momentum Encoder\n        self.momentum_final_block = MomentumFinalBlock(self.final_block, momentum=self.config.MOMENTUM)\n\n        # Spatial Attention\n        self.spatial_attention = SpatialAttention(self.feature_dim, reduction=self.config.ATTENTION_REDUCTION)\n\n        # Memory Bank\n        self.memory_bank = MemoryBank(\n            self.feature_dim, \n            bank_size=self.config.BANK_SIZE, \n            rarity_threshold=self.config.RARITY_THRESHOLD\n        )\n\n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.BatchNorm1d(self.feature_dim),\n            nn.Linear(self.feature_dim, self.config.HIDDEN_DIM),\n            nn.ReLU(),\n            nn.Dropout(self.config.DROPOUT_RATE),\n            nn.Linear(self.config.HIDDEN_DIM, num_classes)\n        )\n        self.model_name = model_name\n\n    def forward(self, x):\n        # Extract features\n        backbone_features = self.backbone(x)\n        main_features = self.final_block(backbone_features)\n        with torch.no_grad():\n            momentum_features = self.momentum_final_block(backbone_features)\n\n        # Spatial attention and ROI extraction\n        attention_map = self.spatial_attention(main_features)\n        roi_features = main_features * attention_map\n        roi_pooled = F.adaptive_avg_pool2d(roi_features, (1, 1)).flatten(1)\n\n        # Momentum features\n        momentum_pooled = F.adaptive_avg_pool2d(momentum_features, (1, 1)).flatten(1)\n\n        # Combine ROI and momentum features (simple addition)\n        fused_features = roi_pooled + momentum_pooled\n\n        # Update and retrieve from memory bank\n        if self.training:\n            mean_norm = torch.mean(torch.norm(fused_features, dim=1))\n            rarity_scores = torch.abs(torch.norm(fused_features, dim=1) - mean_norm) / mean_norm\n            self.memory_bank.update(fused_features.detach(), rarity_scores)\n        \n        memory_features = self.memory_bank.retrieve(fused_features, k=self.config.RETRIEVAL_K)\n        enhanced_features = fused_features + memory_features\n\n        # Classification\n        out = self.classifier(enhanced_features)\n\n        # Update momentum encoder during training\n        if self.training:\n             self.momentum_final_block.update(self.final_block)\n\n        return out\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:57.029035Z","iopub.execute_input":"2025-05-31T01:35:57.029314Z","iopub.status.idle":"2025-05-31T01:35:57.057798Z","shell.execute_reply.started":"2025-05-31T01:35:57.029276Z","shell.execute_reply":"2025-05-31T01:35:57.057017Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Train Script","metadata":{}},{"cell_type":"code","source":"from fastai.vision.all import *\nimport torch.nn as nn\nimport torch\nimport torchvision.models as models\nfrom copy import deepcopy\n\n# Focal Loss Implementation\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n        \"\"\"\n        Focal Loss to address class imbalance and hard sample mining\n        \n        Args:\n            alpha (float): Weighting factor for positive samples\n            gamma (float): Focusing parameter\n            reduction (str): Reduction method ('mean', 'sum', or 'none')\n        \"\"\"\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        \"\"\"\n        Compute focal loss\n        \n        Args:\n            inputs (torch.Tensor): Model predictions (logits)\n            targets (torch.Tensor): Ground truth labels\n        \n        Returns:\n            torch.Tensor: Computed loss\n        \"\"\"\n        # Apply sigmoid to convert logits to probabilities\n        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        \n        # Focal Loss modification\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n        \n        if self.reduction == 'mean':\n            return torch.mean(F_loss)\n        elif self.reduction == 'sum':\n            return torch.sum(F_loss)\n        else:\n            return F_loss\n\n# Asymmetric Loss Implementation\nclass AsymmetricLoss(nn.Module):\n    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, reduction='mean'):\n        \"\"\"\n        Asymmetric Loss to handle class imbalance and hard negative mining\n        \n        Args:\n            gamma_neg (float): Focusing parameter for negative samples\n            gamma_pos (float): Focusing parameter for positive samples\n            clip (float): Clip the predictions to prevent extreme values\n            eps (float): Small epsilon to prevent log(0)\n            reduction (str): Reduction method ('mean', 'sum', or 'none')\n        \"\"\"\n        super(AsymmetricLoss, self).__init__()\n        self.gamma_neg = gamma_neg\n        self.gamma_pos = gamma_pos\n        self.clip = clip\n        self.eps = eps\n        self.reduction = reduction\n\n    def forward(self, x, y):\n        \"\"\"\n        Compute asymmetric loss\n        \n        Args:\n            x (torch.Tensor): Model predictions (logits)\n            y (torch.Tensor): Ground truth labels\n        \n        Returns:\n            torch.Tensor: Computed loss\n        \"\"\"\n        # Convert to probabilities\n        x_sigmoid = torch.sigmoid(x)\n        \n        # Clip predictions to prevent extreme values\n        xs_min = x_sigmoid.clamp(min=self.eps)\n        xs_max = x_sigmoid.clamp(max=1-self.eps)\n        \n        # Asymmetric term for positive and negative samples\n        loss_pos = -y * torch.log(xs_min) * torch.pow(1 - xs_min, self.gamma_pos)\n        loss_neg = -(1 - y) * torch.log(1 - xs_max) * torch.pow(xs_max, self.gamma_neg)\n        \n        loss = loss_pos + loss_neg\n        \n        if self.reduction == 'mean':\n            return torch.mean(loss)\n        elif self.reduction == 'sum':\n            return torch.sum(loss)\n        else:\n            return loss\n\n# Create a custom fastai Learner for ChestXrayModel\ndef create_fastai_learner(\n    dls,                            # DataLoaders object\n    num_classes=14,                 # Number of output classes\n    lr=1e-4,                        # Learning rate\n    momentum=0.9,                   # Momentum for the momentum encoder (aligned with model)\n    dropout_rate=0.3,               # Dropout rate for classifier\n    mixup=False,                    # Whether to use mixup augmentation\n    wd=1e-2,                        # Weight decay\n    model=None,                     # Pass a pre-instantiated model if you have one\n    cbs=None,                       # Additional callbacks\n    warmup_epochs=0,                # Number of warm-up epochs for momentum encoder\n    loss_type='focal',              # Loss type: 'focal' or 'asymmetric'\n    focal_alpha=1,                  # Focal loss alpha parameter\n    focal_gamma=2,                  # Focal loss gamma parameter\n    asymmetric_gamma_neg=4,         # Asymmetric loss gamma for negative samples\n    asymmetric_gamma_pos=1          # Asymmetric loss gamma for positive samples\n):\n    # Create model if not provided\n    if model is None:\n        model = ChestXrayModel(\n            num_classes=num_classes\n        )\n    \n    # Register a custom callback to update momentum encoder with warm-up\n    class MomentumUpdateCallback(Callback):\n        def __init__(self, warmup_epochs):\n            super().__init__()\n            self.warmup_epochs = warmup_epochs\n        \n        def after_batch(self):\n            if hasattr(self.learn.model, 'momentum_final_block'):\n                # Apply warm-up during the first few epochs\n                is_warmup = self.learn.epoch < self.warmup_epochs\n                self.learn.model.momentum_final_block.update(\n                    self.learn.model.final_block, warmup=is_warmup\n                )\n    \n    # Define a custom loss function with multiple loss options\n    class ChestXrayLoss(Module):\n        def __init__(self, loss_type, **kwargs):\n            super().__init__()\n            if loss_type == 'focal':\n                self.loss = FocalLoss(\n                    #alpha=kwargs.get('focal_alpha', 1),\n                    #gamma=kwargs.get('focal_gamma', 2)\n                )\n            elif loss_type == 'asymmetric':\n                self.loss = AsymmetricLoss(\n                    gamma_neg=kwargs.get('asymmetric_gamma_neg', 4),\n                    gamma_pos=kwargs.get('asymmetric_gamma_pos', 1)\n                )\n            elif loss_type == 'bce':\n                self.loss = nn.BCEWithLogitsLoss()\n            else:\n                raise ValueError(f\"Unsupported loss type: {loss_type}\")\n        \n        def forward(self, preds, targets):\n            return self.loss(preds, targets)\n    \n    # Prepare default callbacks\n    default_cbs = [\n        MomentumUpdateCallback(warmup_epochs),  # Custom callback with warm-up\n        SaveModelCallback(monitor='valid_loss'),  # Save best model\n        EarlyStoppingCallback(monitor='valid_loss', patience=3)  # Early stopping\n    ]\n    \n    # Add user-specified callbacks\n    if cbs is not None:\n        if isinstance(cbs, list):\n            default_cbs.extend(cbs)\n        else:\n            default_cbs.append(cbs)\n    \n    # Create the learner with custom model and loss\n    learn = Learner(\n        dls, \n        model, \n        loss_func=ChestXrayLoss(\n            loss_type=loss_type, \n            focal_alpha=focal_alpha, \n            focal_gamma=focal_gamma,\n            asymmetric_gamma_neg=asymmetric_gamma_neg,\n            asymmetric_gamma_pos=asymmetric_gamma_pos\n        ),\n        metrics=[accuracy_multi, F1ScoreMulti(), RocAucMulti()],  # Multi-label metrics\n        wd=wd,\n        cbs=default_cbs\n    )\n    \n    # Modify the model's forward method to work with fastai's expectations\n    class ModelWrapper(nn.Module):\n        def __init__(self, model):\n            super().__init__()\n            self.model = model\n        \n        def forward(self, x):\n            return self.model(x)  # Model returns only class predictions\n    \n    # Wrap the model\n    learn.model = ModelWrapper(learn.model)\n    \n    # Enable mixed precision training if available\n    learn.to_fp16()\n    \n    # Add mixup if requested (suitable for multi-label with BCE)\n    if mixup:\n        learn.add_cb(MixUp())\n    \n    # Add a progress bar callback for better training visualization\n    learn.add_cb(ProgressCallback())\n    \n    # Add CSV logger to track metrics\n    learn.add_cb(CSVLogger())\n    \n    return learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:57.059284Z","iopub.execute_input":"2025-05-31T01:35:57.059699Z","iopub.status.idle":"2025-05-31T01:35:57.089155Z","shell.execute_reply.started":"2025-05-31T01:35:57.059646Z","shell.execute_reply":"2025-05-31T01:35:57.088458Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Stage 2","metadata":{}},{"cell_type":"code","source":"import fastai\nfrom fastai.vision.all import *\nfrom tqdm import tqdm\nfrom glob import glob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:57.091903Z","iopub.execute_input":"2025-05-31T01:35:57.092128Z","iopub.status.idle":"2025-05-31T01:35:57.110619Z","shell.execute_reply.started":"2025-05-31T01:35:57.092112Z","shell.execute_reply":"2025-05-31T01:35:57.109898Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#learn = learn.load('/kaggle/working/models/fastai_momentum_cross_spatial_70_20_10')\nSEED = 85\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(SEED)\nlabels_train_val = pd.read_csv('/kaggle/input/data/train_val_list.txt')\nlabels_train_val.columns = ['Image_Index']\nlabels_test = pd.read_csv('/kaggle/input/data/test_list.txt')\nlabels_test.columns = ['Image_Index']\ndisease_labels = ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening',\n'Cardiomegaly', 'Nodule', 'Mass', 'Hernia']\n# NIH Dataset Labels CSV File \nlabels_df = pd.read_csv('/kaggle/input/data/Data_Entry_2017.csv')\nlabels_df.columns = ['Image_Index', 'Finding_Labels', 'Follow_Up_#', 'Patient_ID',\n                  'Patient_Age', 'Patient_Gender', 'View_Position',\n                  'Original_Image_Width', 'Original_Image_Height',\n                  'Original_Image_Pixel_Spacing_X',\n                  'Original_Image_Pixel_Spacing_Y', 'dfd']\n# One hot encoding\nfor diseases in tqdm(disease_labels): \n    labels_df[diseases] = labels_df['Finding_Labels'].map(lambda result: 1 if diseases in result else 0)\n\n# labels_df.to_csv('/kaggle/working/newData.csv')\n# labels_df=labels_df[labels_df.Finding_Labels != 'No Finding']\n# #labels_df.head(3)\n\nlabels_df['Finding_Labels'] = labels_df['Finding_Labels'].apply(lambda s: [l for l in str(s).split('|')])\n\nnum_glob = glob('/kaggle/input/data/*/images/*.png')\nimg_path = {os.path.basename(x): x for x in num_glob}\n\nlabels_df['Paths'] = labels_df['Image_Index'].map(img_path.get)\nlabels_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:57.111512Z","iopub.execute_input":"2025-05-31T01:35:57.112044Z","iopub.status.idle":"2025-05-31T01:35:58.557100Z","shell.execute_reply.started":"2025-05-31T01:35:57.112017Z","shell.execute_reply":"2025-05-31T01:35:58.556221Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 14/14 [00:00<00:00, 26.01it/s]\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"        Image_Index             Finding_Labels  Follow_Up_#  Patient_ID  \\\n0  00000001_000.png             [Cardiomegaly]            0           1   \n1  00000001_001.png  [Cardiomegaly, Emphysema]            1           1   \n2  00000001_002.png   [Cardiomegaly, Effusion]            2           1   \n3  00000002_000.png               [No Finding]            0           2   \n4  00000003_000.png                   [Hernia]            0           3   \n\n   Patient_Age Patient_Gender View_Position  Original_Image_Width  \\\n0           58              M            PA                  2682   \n1           58              M            PA                  2894   \n2           58              M            PA                  2500   \n3           81              M            PA                  2500   \n4           81              F            PA                  2582   \n\n   Original_Image_Height  Original_Image_Pixel_Spacing_X  ...  Emphysema  \\\n0                   2749                           0.143  ...          0   \n1                   2729                           0.143  ...          1   \n2                   2048                           0.168  ...          0   \n3                   2048                           0.171  ...          0   \n4                   2991                           0.143  ...          0   \n\n   Fibrosis  Effusion  Pneumonia  Pleural_Thickening  Cardiomegaly  Nodule  \\\n0         0         0          0                   0             1       0   \n1         0         0          0                   0             1       0   \n2         0         1          0                   0             1       0   \n3         0         0          0                   0             0       0   \n4         0         0          0                   0             0       0   \n\n   Mass  Hernia                                                  Paths  \n0     0       0  /kaggle/input/data/images_001/images/00000001_000.png  \n1     0       0  /kaggle/input/data/images_001/images/00000001_001.png  \n2     0       0  /kaggle/input/data/images_001/images/00000001_002.png  \n3     0       0  /kaggle/input/data/images_001/images/00000002_000.png  \n4     0       1  /kaggle/input/data/images_001/images/00000003_000.png  \n\n[5 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_Index</th>\n      <th>Finding_Labels</th>\n      <th>Follow_Up_#</th>\n      <th>Patient_ID</th>\n      <th>Patient_Age</th>\n      <th>Patient_Gender</th>\n      <th>View_Position</th>\n      <th>Original_Image_Width</th>\n      <th>Original_Image_Height</th>\n      <th>Original_Image_Pixel_Spacing_X</th>\n      <th>...</th>\n      <th>Emphysema</th>\n      <th>Fibrosis</th>\n      <th>Effusion</th>\n      <th>Pneumonia</th>\n      <th>Pleural_Thickening</th>\n      <th>Cardiomegaly</th>\n      <th>Nodule</th>\n      <th>Mass</th>\n      <th>Hernia</th>\n      <th>Paths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000001_000.png</td>\n      <td>[Cardiomegaly]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2682</td>\n      <td>2749</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000001_000.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000001_001.png</td>\n      <td>[Cardiomegaly, Emphysema]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2894</td>\n      <td>2729</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000001_001.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000001_002.png</td>\n      <td>[Cardiomegaly, Effusion]</td>\n      <td>2</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.168</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000001_002.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000002_000.png</td>\n      <td>[No Finding]</td>\n      <td>0</td>\n      <td>2</td>\n      <td>81</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.171</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000002_000.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000003_000.png</td>\n      <td>[Hernia]</td>\n      <td>0</td>\n      <td>3</td>\n      <td>81</td>\n      <td>F</td>\n      <td>PA</td>\n      <td>2582</td>\n      <td>2991</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>/kaggle/input/data/images_001/images/00000003_000.png</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"unique_patients = np.unique(labels_df['Patient_ID'])\nlen(unique_patients)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:58.558025Z","iopub.execute_input":"2025-05-31T01:35:58.558395Z","iopub.status.idle":"2025-05-31T01:35:58.567541Z","shell.execute_reply.started":"2025-05-31T01:35:58.558368Z","shell.execute_reply":"2025-05-31T01:35:58.566595Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"30805"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# train-70\n# val-10\n# test-20\ntrain_val_df_patients, test_df_patients = train_test_split(unique_patients, \n                                   test_size = 0.2,\n                                   random_state = SEED,\n                                    shuffle= True\n                                   )\nlen(train_val_df_patients)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:58.568477Z","iopub.execute_input":"2025-05-31T01:35:58.568709Z","iopub.status.idle":"2025-05-31T01:35:58.584327Z","shell.execute_reply.started":"2025-05-31T01:35:58.568690Z","shell.execute_reply":"2025-05-31T01:35:58.583520Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"24644"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"train_val_df = labels_df[labels_df['Patient_ID'].isin(train_val_df_patients)]\ntest_df = labels_df[labels_df['Patient_ID'].isin(test_df_patients)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:58.585247Z","iopub.execute_input":"2025-05-31T01:35:58.585581Z","iopub.status.idle":"2025-05-31T01:35:58.646382Z","shell.execute_reply.started":"2025-05-31T01:35:58.585563Z","shell.execute_reply":"2025-05-31T01:35:58.645450Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"labels_df.shape\nprint('train_val size', train_val_df.shape[0])\nprint('test size', labels_df.shape[0] - train_val_df.shape[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:58.647165Z","iopub.execute_input":"2025-05-31T01:35:58.647407Z","iopub.status.idle":"2025-05-31T01:35:58.652851Z","shell.execute_reply.started":"2025-05-31T01:35:58.647387Z","shell.execute_reply":"2025-05-31T01:35:58.652049Z"}},"outputs":[{"name":"stdout","text":"train_val size 89764\ntest size 22356\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"item_transforms = [\n    Resize((224, 224)),\n]\n\nbatch_transforms = [\n    Flip(),\n    Rotate(),\n    Normalize.from_stats(*imagenet_stats),\n]\n\n\ndef get_x(row):\n    return row['Paths']\n\ndef get_y(row):\n    labels = row[disease_labels].tolist()\n    return labels\n\ndblock = DataBlock(\n    blocks=(ImageBlock, MultiCategoryBlock(encoded=True,vocab=disease_labels)),\n                   splitter=RandomSplitter(valid_pct=0.125, seed=SEED),\n                   get_x=get_x,\n                   get_y=get_y,\n                   item_tfms=item_transforms,\n                   batch_tfms=batch_transforms\n                  )\ndls_phase2 = dblock.dataloaders(train_val_df, bs=128)\ncbs_phase2=[\n    SaveModelCallback(monitor='valid_loss', min_delta=0.0001, with_opt=True),\n    EarlyStoppingCallback(monitor='valid_loss', min_delta=0.001, patience=5),\n    ShowGraphCallback()\n    ]\ndls_test = dblock.dataloaders(test_df, bs=32, shuffle=False)\n# print(dblock.datasets(train_val_merge).train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:58.653669Z","iopub.execute_input":"2025-05-31T01:35:58.653927Z","iopub.status.idle":"2025-05-31T01:35:59.627027Z","shell.execute_reply.started":"2025-05-31T01:35:58.653907Z","shell.execute_reply":"2025-05-31T01:35:59.625982Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\ndef get_roc_auc(learner):\n    #arch = model_arch\n    # learner = vision_learner(dls, arch, metrics=[accuracy_multi, F1ScoreMulti(), RocAucMulti()])\n    # learner.model = torch.nn.DataParallel(learner.model)\n    # learner.load(model_path)\n    # learner.to('cuda')\n    learner.freeze()\n    preds, y_test = learner.get_preds(ds_idx=1)\n    roc_auc = roc_auc_score(y_test, preds)\n    \n    scores=[]\n    for i in range(0,14):\n        label_roc_auc_score=roc_auc_score(y_test[:,i],preds[:,i])\n        scores.append(label_roc_auc_score)\n    print('ROC_AUC_Labels:', list(zip(disease_labels,scores)))   \n    \n#     print('AVERAGE', sum(scores)/len(scores))\n    print(f'SCORE: {roc_auc}')\n    del learner\n    #gc.collect()\n    return {\n        'roc_auc': roc_auc,\n        'preds': preds,\n        'y_test': y_test\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:59.628417Z","iopub.execute_input":"2025-05-31T01:35:59.628775Z","iopub.status.idle":"2025-05-31T01:35:59.635011Z","shell.execute_reply.started":"2025-05-31T01:35:59.628746Z","shell.execute_reply":"2025-05-31T01:35:59.634071Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from fastai.vision.all import *\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score\nimport itertools\nimport time\nimport os\n\n\n# Define the parameter grid\nmomentum_values = [0.99]\nk_values = [5]\nthreshold_values = [0.2]\n\n# Define results directory\nresults_dir = '/kaggle/working/parameter_search_results'\nos.makedirs(results_dir, exist_ok=True)\n\n# Prepare to store results\nresults = []\n\n# Define base callbacks for all runs\nbase_cbs = [\n    SaveModelCallback(monitor='valid_loss', min_delta=0.0001, with_opt=True),\n    EarlyStoppingCallback(monitor='valid_loss', min_delta=0.001, patience=3),\n    ShowGraphCallback()\n    ]\ndef run_experiment(momentum, k, threshold, exp_name):\n    \"\"\"Run a single experiment with specified parameters.\"\"\"\n    print(f\"\\n=== Running experiment: momentum={momentum}, k={k}, threshold={threshold} ===\")\n    \n    # Modify the ModelConfig class attributes directly\n    ModelConfig.MOMENTUM = momentum\n    ModelConfig.RETRIEVAL_K = k\n    ModelConfig.RARITY_THRESHOLD = threshold\n    \n    # Create a model-specific save callback\n    save_cb = SaveModelCallback(monitor='valid_loss', min_delta=0.0001, \n                             fname=f\"model_{exp_name}\", with_opt=True)\n    \n    # Combine callbacks\n    cbs = base_cbs + [save_cb]\n    \n    try:\n        start_time = time.time()\n        \n        \n        # Testing phase\n        print('--------------Begin-Testing---------------')\n        test_learn = create_fastai_learner(dls_test, cbs=cbs, loss_type='asymmetric')\n        test_learn = test_learn.load(f\"/kaggle/input/best-model/model_{exp_name}\")\n        \n        # Get results\n        model_result = get_roc_auc(test_learn)\n        preds = model_result['preds']\n        auc_scores = model_result['class_auc']\n        mean_auc = model_result['mean_auc']\n        \n        training_time = time.time() - start_time\n        \n        result = {\n            'momentum': momentum,\n            'k': k,\n            'threshold': threshold,\n            'mean_auc': mean_auc,\n            'class_auc': auc_scores,\n            'training_time': training_time,\n            'exp_name': exp_name\n        }\n        \n        print(f\"Experiment completed. Mean AUC: {mean_auc:.4f}, Time: {training_time:.1f}s\")\n        return result\n        \n    except Exception as e:\n        print(f\"Error in experiment: {str(e)}\")\n        return {\n            'momentum': momentum,\n            'k': k,\n            'threshold': threshold,\n            'mean_auc': float('nan'),\n            'class_auc': [],\n            'training_time': float('nan'),\n            'exp_name': exp_name,\n            'error': str(e)\n        }\n\n# Main script\nif __name__ == \"__main__\":\n    # Get all parameter combinations\n    all_combinations = list(itertools.product(momentum_values, k_values, threshold_values))\n    total_experiments = len(all_combinations)\n    \n    print(f\"Starting grid search with {total_experiments} parameter combinations\")\n    \n    # Run all experiments\n    for i, (momentum, k, threshold) in enumerate(all_combinations):\n        exp_name = f\"m{momentum}_k{k}_t{threshold}\"\n        print(f\"\\nExperiment {i+1}/{total_experiments}\")\n        \n        result = run_experiment(momentum, k, threshold, exp_name)\n        results.append(result)\n        \n        # Save intermediate results after each experiment\n        pd.DataFrame(results).to_csv(f'{results_dir}/grid_search_results.csv', index=False)\n    \n    # Convert results to DataFrame for analysis\n    results_df = pd.DataFrame(results)\n    \n        \n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:35:59.635950Z","iopub.execute_input":"2025-05-31T01:35:59.636240Z","iopub.status.idle":"2025-05-31T01:36:55.571251Z","shell.execute_reply.started":"2025-05-31T01:35:59.636215Z","shell.execute_reply":"2025-05-31T01:36:55.570339Z"}},"outputs":[{"name":"stdout","text":"Starting grid search with 1 parameter combinations\n\nExperiment 1/1\n\n=== Running experiment: momentum=0.99, k=5, threshold=0.2 ===\n--------------Phase2-Done---------------\n--------------Begin-Testing---------------\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n100%|██████████| 82.7M/82.7M [00:00<00:00, 157MB/s] \n/usr/local/lib/python3.11/dist-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(file, map_location=device, **torch_load_kwargs)\n/usr/local/lib/python3.11/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/usr/local/lib/python3.11/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"ROC_AUC_Labels: [('Atelectasis', 0.8333766499098691), ('Consolidation', 0.8193751479949299), ('Infiltration', 0.7392748233045947), ('Pneumothorax', 0.9082326043365004), ('Edema', 0.9184891395283983), ('Emphysema', 0.9456263001007913), ('Fibrosis', 0.8608682664542467), ('Effusion', 0.9169705331625111), ('Pneumonia', 0.7758288136887939), ('Pleural_Thickening', 0.8781900685482574), ('Cardiomegaly', 0.931487046601045), ('Nodule', 0.8301141886623157), ('Mass', 0.9090395702306079), ('Hernia', 0.9854181622397704)]\nSCORE: 0.875163665340188\nError in experiment: 'class_auc'\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}